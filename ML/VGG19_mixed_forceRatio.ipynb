{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import ConcatDataset, DataLoader, random_split, SubsetRandomSampler, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3077727623"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0, 2**32 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomSeed=42\n",
    "#randomSeed=random.randint(0, 2**32 - 1)\n",
    "randomSeed=3077727623\n",
    "VGGMode=True\n",
    "modelName=\"VGG19\"\n",
    "if VGGMode:\n",
    "    modelName=\"VGG19_0\"\n",
    "else:\n",
    "    modelName=\"VGG19_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load your data\n",
    "train_datasets=[]\n",
    "val_datasets=[]\n",
    "test_datasets=[]\n",
    "test_loader_image=None\n",
    "test_loader_tactile=None\n",
    "for path in ['Data_tactile','Data']:\n",
    "    #dataset = datasets.ImageFolder('Data', transform=transform)\n",
    "    dataset = datasets.ImageFolder(path, transform=transform)\n",
    "\n",
    "    # Force the data to be balanced\n",
    "    targets = [t[1] for t in dataset]\n",
    "    class_indices = [np.where(np.array(targets) == i)[0] for i in range(10)]\n",
    "\n",
    "    # Split the data into training, validation and testing sets\n",
    "    train_indices = []\n",
    "    val_indices = []\n",
    "    test_indices = []\n",
    "    test_mixed_indices = []\n",
    "\n",
    "    np.random.seed(randomSeed)  # Ensure reproducibility\n",
    "    for class_index in class_indices:\n",
    "        np.random.shuffle(class_index)\n",
    "        split_train = int(np.floor(0.7 * len(class_index)))\n",
    "        split_val = int(np.floor(0.8 * len(class_index)))\n",
    "        split_test1 = int(np.floor(0.9 * len(class_index)))\n",
    "        \n",
    "        train_indices.extend(class_index[:split_train])\n",
    "        val_indices.extend(class_index[split_train:split_val])\n",
    "        test_indices.extend(class_index[split_val:split_test1])\n",
    "        test_mixed_indices.extend(class_index[split_test1:])\n",
    "    \n",
    "    # Create the datasets\n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    val_dataset = Subset(dataset, val_indices)\n",
    "    test_dataset = Subset(dataset, test_indices)\n",
    "    testMix_dataset = Subset(dataset, test_mixed_indices)\n",
    "    \n",
    "    if path=='Data':\n",
    "        test_loader_image = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "    else:\n",
    "        test_loader_tactile = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # Append the datasets \n",
    "    train_datasets.append(train_dataset)\n",
    "    val_datasets.append(val_dataset)\n",
    "    test_datasets.append(testMix_dataset)\n",
    "\n",
    "# Merge the data\n",
    "train_dataset = ConcatDataset(train_datasets)\n",
    "val_dataset = ConcatDataset(val_datasets)\n",
    "test_dataset = ConcatDataset(test_datasets)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Save DataLoader for later testing\n",
    "with open(modelName+'_dataloader_mixed.pkl', 'wb') as f:\n",
    "    pickle.dump(test_loader, f)\n",
    "with open(modelName+'_dataloader_image.pkl', 'wb') as f:\n",
    "    pickle.dump(test_loader_image, f)\n",
    "with open(modelName+'_dataloader_tactile.pkl', 'wb') as f:\n",
    "    pickle.dump(test_loader_tactile, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if CUDA is available and set PyTorch to use GPU or CPU accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr_list=[0.1,0.01,0.001,0.0001]\n",
    "if VGGMode:\n",
    "    momentum_list=[0.6,0.99]\n",
    "else:\n",
    "    momentum_list=[0.3,0.9]\n",
    "epochs=100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\49228\\anaconda3\\envs\\ML\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\49228\\anaconda3\\envs\\ML\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.1, momentum: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/100000 [02:33<4271:20:08, 153.77s/it]"
     ]
    }
   ],
   "source": [
    "with open('VGG19_log.txt', 'w', newline='') as recordFile:\n",
    "    for lr_i in lr_list:\n",
    "        for momentum_i in momentum_list:\n",
    "            # Load the pretrained alexnet model\n",
    "            model = models.vgg19(pretrained=True)\n",
    "\n",
    "            # Move the model to the GPU if available\n",
    "            model = model.to(device)\n",
    "\n",
    "            # Assuming your images are labeled from 0 to 9\n",
    "            num_ftrs = model.classifier[6].in_features\n",
    "            model.classifier[6] = nn.Linear(num_ftrs, 10)\n",
    "            optimizer = optim.SGD(model.parameters(), lr=lr_i, momentum=momentum_i)\n",
    "            # Train the model\n",
    "            prev_loss_f1 = -1\n",
    "            print(f\"lr: {lr_i}, momentum: {momentum_i}\")\n",
    "            recordFile.write(f\"lr: {lr_i}, momentum: {momentum_i} : \")\n",
    "            with open(f'Scores/VGG19t_lr{lr_i}_momentum{momentum_i}.csv', 'w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(['Train F1', 'Test F1', 'Saved'])\n",
    "            with open(f'Scores/VGG19t_lr{lr_i}_momentum{momentum_i}.csv', 'a', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "\n",
    "                repeat_checker=0\n",
    "                repeat_val_f1=0\n",
    "                sw=True\n",
    "                for epoch in tqdm(range(epochs)):  # Maximum number of epochs\n",
    "                    all_preds = []\n",
    "                    all_labels = []\n",
    "\n",
    "                    model.train()  # Set the model to training mode\n",
    "                    for inputs, labels in train_loader:\n",
    "                        inputs=inputs.to(device)\n",
    "                        labels=labels.to(device)\n",
    "                        model.to(device)\n",
    "                        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "                        outputs = model(inputs)  # Forward pass\n",
    "                        loss = criterion(outputs, labels)  # Compute loss\n",
    "                        loss.backward()  # Backward pass\n",
    "                        optimizer.step()  # Optimize\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                    train_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                    #print(f\"Epoch {epoch+1}, Train F1: {f1}\")\n",
    "\n",
    "                    # Validation phase\n",
    "                    all_preds = []\n",
    "                    all_labels = []\n",
    "                    model.eval()  # Set the model to evaluation mode\n",
    "                    for inputs, labels in val_loader:\n",
    "                        inputs, labels = inputs.to(device), labels.to(device)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                    test_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                    #print(f\"Epoch {epoch+1}, Test F1: {f1}\")\n",
    "                    # Save the model if the test loss is lower than the previous one\n",
    "                    saved = \"N\"\n",
    "                    if test_f1 > prev_loss_f1:\n",
    "                        torch.save(model.state_dict(), f'Model/VGG19_lr{lr_i}_momentum{momentum_i}.pth')\n",
    "                        prev_loss_f1 = test_f1\n",
    "                        saved = \"Y\"\n",
    "                    writer.writerow([train_f1, test_f1, saved])\n",
    "\n",
    "                    # If F1 score is not improving, stop the training\n",
    "                    if repeat_val_f1==test_f1:\n",
    "                        repeat_checker+=1\n",
    "                        if repeat_checker>20:\n",
    "                            print('F1 score is not improving. Stopping training.')\n",
    "                            recordFile.write(f\"F1 score is not improving. Stopping training. epoch : {epoch} \\n\")\n",
    "                            sw=False\n",
    "                            break\n",
    "                    else:\n",
    "                        repeat_checker=0\n",
    "                        repeat_val_f1=test_f1\n",
    "                        \n",
    "                    # If the val loss is low enough, stop the training\n",
    "                    if test_f1 > 0.995:  # Set your threshold here\n",
    "                        print('F1 score is high enough. Stopping training.')\n",
    "                        recordFile.write(f\"F1 score is high enough. Stopping training. epoch : {epoch} \\n\")\n",
    "                        sw=False\n",
    "                        break\n",
    "                    \n",
    "                    # If the train loss is low enough, stop the training\n",
    "                    if train_f1>0.999:\n",
    "                        print('Train F1 score is high enough. Stopping training.')\n",
    "                        recordFile.write(f\"Train F1 score is high enough. Stopping training. epoch : {epoch} \\n\")\n",
    "                        sw=False\n",
    "                        break\n",
    "\n",
    "                    \n",
    "                if sw:\n",
    "                    recordFile.write(f\"model run finished without no problem epoch : {epochs}\\n\")\n",
    "                # Test the model of mixed\n",
    "                num_samples = 0\n",
    "                num_correct = 0\n",
    "                for inputs, labels in test_loader:\n",
    "                    inputs=inputs.to(device)\n",
    "                    labels=labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "                    num_samples += labels.size(0)\n",
    "                    num_correct += (preds == labels).sum().item()\n",
    "                test_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                acc = num_correct / num_samples\n",
    "                recordFile.write(f\"Mixed = Test F1: {test_f1}, Test Accuracy: {acc}\\n\")\n",
    "\n",
    "                # Test the model of image\n",
    "                num_samples = 0\n",
    "                num_correct = 0\n",
    "                for inputs, labels in test_loader_image:\n",
    "                    inputs=inputs.to(device)\n",
    "                    labels=labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "                    num_samples += labels.size(0)\n",
    "                    num_correct += (preds == labels).sum().item()\n",
    "                test_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                acc = num_correct / num_samples\n",
    "                recordFile.write(f\"Image = Test F1: {test_f1}, Test Accuracy: {acc}\\n\")\n",
    "\n",
    "                # Test the model of tactile\n",
    "                num_samples = 0\n",
    "                num_correct = 0\n",
    "                for inputs, labels in test_loader_tactile:\n",
    "                    inputs=inputs.to(device)\n",
    "                    labels=labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "                    num_samples += labels.size(0)\n",
    "                    num_correct += (preds == labels).sum().item()\n",
    "                test_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                acc = num_correct / num_samples\n",
    "                recordFile.write(f\"Tactile = Test F1: {test_f1}, Test Accuracy: {acc}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
